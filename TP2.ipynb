{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d7dbaa92",
   "metadata": {},
   "source": [
    "# TP2 : Estimation de densité par noyaux\n",
    "\n",
    "## Introduction à l'estimation statistique - G3 SDIA\n",
    "\n",
    "Dans le cadre de cours, nous avons étudié jusqu'à présent des méthodes d'estimation dites paramétriques : on se fixe une famille de lois paramétrique à laquelle la loi ayant généré les données est censée appartenir, puis on cherche à estimer les paramètres à partir des données (par exemple par maximum de vraisemblance).\n",
    "\n",
    "Dans ce TP, nous introduisons une méthode d'estimation **non-paramétrique** de la fonction de densité appelée estimation par noyaux (*kernel estimation* en anglais). C'est-à-dire que nous ne faisons plus d'hypothèse sur la loi ayant généré les données, et nous cherchons plutôt à estimer directement la densité de la loi parente $f$ (que l'on supposera continue). Ainsi cette méthode ne concerne que les variables aléatoires continues.\n",
    "\n",
    "### Instructions\n",
    "\n",
    "1. Renommer votre notebook sous la forme `tp1_Nom1_Nom2.ipynb`, et inclure le nom du binôme dans le notebook. \n",
    "\n",
    "2. Votre code, ainsi que toute sortie du code, doivent être commentés !\n",
    "\n",
    "3. Déposer votre notebook sur Moodle dans la section prévue à cet effet avant la date limite : 22 Octobre 2023, 23h59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96c8adb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import scipy.stats as ss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d67bcb52",
   "metadata": {},
   "source": [
    "### Partie 1 - Histogrammes\n",
    "\n",
    "On considère $(x_1, ..., x_n)$ $n$ réalisations indépendantes d'une variable aléatoire réelle.\n",
    "\n",
    "Soit $x_0 \\in \\mathbb{R}$ et $h > 0$. On partitionne la droite réelle en intervalles de même longueur $h$, aussi appelés *bins* :\n",
    "$$\\forall k \\in \\mathbb{Z},~B_k =~]x_0 + (k-1)h~;~x_0 + kh].$$\n",
    "\n",
    "L'histogramme est une fonction constante par morceaux définie de la manière suivante :\n",
    "$$\\forall x \\in B_k,~H_n(x) = n_k,$$\n",
    "où $n_k$ est le nombre de réalisations appartenant à l'intervalle $B_k$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e2aa2f",
   "metadata": {},
   "source": [
    "**Q1**. Comment normaliser $H_n$ pour obtenir un estimateur de la fonction de densité ? On rappelera que $\\int_{\\mathbb{R}} f(x) dx = 1$.\n",
    "\n",
    "Dans la suite, on note $\\hat{f}_n$ cet estimateur de $f$.\n",
    "\n",
    "Pour tout $x \\in \\mathbb{R}$, calculer le biais et la variance de $\\hat{f}_n(x)$. Commenter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d6e1355",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73958db",
   "metadata": {},
   "source": [
    "**Q2**. On fixe $x_0 = \\min_i x_i$. La valeur de $h$ peut être fixée indirectement en fixant à la place le nombre de *bins* $N_b$ entre $\\min_i x_i$ et $\\max_i x_i$, on a alors\n",
    "$$h = \\frac{\\max_i x_i - \\min_i x_i}{N_b}.$$\n",
    "\n",
    "Générer 200 points d'un modèle de mélange gaussien à 2 composantes avec $\\mu_1 = -2.5, \\mu_2 = 1.5, \\sigma_1 = \\sigma_2 = 1, \\pi_1 = 0.4, \\pi_2 = 0.6$.\n",
    "\n",
    "Montrer l'influence de la valeur de $h$ sur l'histogramme (normalisé). On utilisera la fonction $\\texttt{np.histogram}$ pour calculer automatiquement les $n_k$, et la fonction $\\texttt{plt.bar}$ pour représenter $\\hat{f}_n$. Superposer la densité théorique du modèle de mélange gaussien.\n",
    "\n",
    "On pourra afficher plusieurs histogrammes obtenus avec différentes valeurs de $N_b$ à l'aide de $\\texttt{plt.subplots}$. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6d84e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate data from GMM\n",
    "\n",
    "N = 200\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #\n",
    "\n",
    "\n",
    "# Plot histograms with varying number of bins\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d314e9",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d83e407f",
   "metadata": {},
   "source": [
    "**Q3**. Quelles sont les principales limitations de l'utilisation de l'histogramme comme estimateur de la fonction de densité ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecba2af4",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "021ef3dc",
   "metadata": {},
   "source": [
    "### Partie 2 - Estimation par noyaux (en 1D)\n",
    "\n",
    "$(x_1, ..., x_n)$ sont toujours $n$ réalisations indépendantes d'une variable aléatoire réelle.\n",
    "\n",
    "L'une des motivations principales est de faire directement dépendre l'estimation des données, et de ne plus dépendre de découpages arbitraires de $\\mathbb{R}$. Pour cela, on propose la méthodologie suivante :\n",
    "- Choisir une fonction $K$ appelée \"noyau\". On choisit $K$ positive ou nulle, symétrique, et d'intégrale 1.\n",
    "- Centrer $K$ sur chaque observation $x_i$.\n",
    "- L'estimateur à noyaux est alors\n",
    "$$\\hat{f}_n(x) = \\frac{1}{n} \\sum_{i=1}^n K(x - x_i).$$\n",
    "\n",
    "On pourra par exemple choisir des noyaux $K$ continus, dérivables partout... Propriétés dont $\\hat{f}_n$ héritera."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c63a100e",
   "metadata": {},
   "source": [
    "**Q1**. On utilise dans un premier temps un noyau gaussien :\n",
    "$$K(x) = \\frac{1}{\\sqrt{2 \\pi}} \\exp(-\\frac{x^2}{2}).$$\n",
    "\n",
    "Prendre 10 observations des données générées dans la partie 1. Sur un même graphique, représenter les 10 noyaux (normalisés par $n$) centrés sur les observations, et l'estimateur à noyaux $\\hat{f}_n$. Superposer la vraie densité $f$. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92b32d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly select 10 points from previously generated dataset\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #\n",
    "\n",
    "\n",
    "# Implement the kernel density estimator and plot it\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c61fedf3",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e2b2f3e",
   "metadata": {},
   "source": [
    "**Q2**. En réalité, on souhaite faire dépendre cet estimateur d'un paramètre de lissage $h > 0$, qu'on appelle largeur de fenêtre (ou *bandwidth* en anglais).\n",
    "\n",
    "Le (véritable) estimateur à noyaux, aussi appelé méthode de Parzen-Rosenblatt (du nom des deux statisticiens l'ayant développée) est :\n",
    "$$\\hat{f}_n(x) = \\frac{1}{nh} \\sum_{i=1}^n K(\\frac{x - x_i}{h}).$$\n",
    "\n",
    "Vérifier que c'est bien l'estimateur d'une densité.\n",
    "\n",
    "Implémenter cet estimateur sur les données de la partie 1, et montrer l'influence de la valeur de $h$. On pourra encore utiliser $\\texttt{plt.subplots}$. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986b6bd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement the (true) kernel estimator and show the influence of h\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4096e8bf",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06890f99",
   "metadata": {},
   "source": [
    "**Q3.** Nous allons maintenant regarder d'autres noyaux. Cette fois-ci, nous n'implémenterons pas l'estimateur à la main mais ferons appel à la librairie `scikit-learn` qui implémente six noyaux différents (dont le noyau gaussien). La méthode est implémentée dans `sklearn.neighbors.KernelDensity`.\n",
    "\n",
    "Représenter les six noyaux. Commenter.\n",
    "\n",
    "À longueur de fenêtre fixée (par exemple $h = 0.5$), montrer l'influence des différentes fenêtres. On pourra encore utiliser $\\texttt{plt.subplots}$. Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dea0717",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KernelDensity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b5d514d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Represent the 6 different kernels implemented in scikit-learn\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #\n",
    "\n",
    "\n",
    "# Show the influence of the kernel (with fixed bandwidth)\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2469d264",
   "metadata": {},
   "source": [
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac299160",
   "metadata": {},
   "source": [
    "**Q4 (bonus)**. La question du choix de $h$ a été largement étudiée dans la littérature. Par exemple, la librairie `scikit-learn` embarque pour l'argument *bandwidth* deux règles de calcul empiriques appelées règle de Scott et règle de Silvermann, qui fixent la valeur de $h$ en fonction de $n$ et $d$ (la dimension des données).\n",
    "\n",
    "À l'aide d'une notion du cours, pouvez-vous imaginer un critère d'optimalité permettant de fixer la valeur de $h$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e9f4ae0",
   "metadata": {},
   "source": [
    "---- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2460d1e",
   "metadata": {},
   "source": [
    "### Partie 3 : Estimation par noyaux (en 2D)\n",
    "\n",
    "L'estimation de densité par noyaux peut être étendue en $d$ dimensions. On peut alors définir $\\mathbf{H}$ une matrice symmétrique de taille $d \\times d$ définie positive pour les longueurs de fenêtres (NB : `scikit-learn` ne le permet pas et n'a qu'un paramètre scalaire en $d$ dimensions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "398a7b96",
   "metadata": {},
   "source": [
    "**Q1**. Reprendre le dataset *Old Faithful* étudié au TP1, et faire une estimation par noyaux de la densité en utilisant `scikit-learn`. Le choix du noyau et de la longueur de fenêtre est laissé libre.\n",
    "\n",
    "Afficher la densité obtenue. On pourra par exemple la représenter sous forme de *heatmap* avec $\\texttt{plt.imshow}$, ou bien sous la forme d'un *surface plot* (ex. : https://matplotlib.org/stable/gallery/mplot3d/surface3d.html). Commenter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8ebe36e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the \"Old Faithful\" dataset from the Seaborn library\n",
    "\n",
    "import seaborn\n",
    "df = seaborn.load_dataset('geyser')\n",
    "X = df[['duration', 'waiting']].values\n",
    "\n",
    "\n",
    "# Use scikit-learn to estimate the density\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #\n",
    "\n",
    "\n",
    "# Represent the density (imshow or surface plot (or both ?!))\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a4ff2a",
   "metadata": {},
   "source": [
    "---- Votre réponse ici ----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696a4f56",
   "metadata": {},
   "source": [
    "### Partie 4 : Estimation par noyaux (en 64D !) -- Un modèle génératif"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1164291",
   "metadata": {},
   "source": [
    "Une fois la fonction de densité estimée par noyaux, nous pouvons facilement échantillonner de cette loi. Ceci nous permet donc de générer \"de fausses données\". C'est ce que nous allons mettre en oeuvre sur un exemple simple avec des images. Estimer la densité nous permettra donc de créer un générateur d'images.\n",
    "\n",
    "**Q1 (bonus)**. Dans le cas d'un noyau gaussien, expliquer pourquoi il est facile d'échantillonner de la densité estimée."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5f1e62a",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a713bd7a",
   "metadata": {},
   "source": [
    "**Q2.** Dans cette dernière partie, nous considérons le cas où nos données représentent des images. Nous utiliserons le dataset *Digits* qui contient environ 1700 imagettes en niveaux de gris de taille 8 par 8, qui peuvent donc être représentées comme des vecteurs de taille 64. Ces imagettes représentent des numéros scannés de codes postaux.\n",
    "\n",
    "- Estimer par noyaux de la densité en utilisant `scikit-learn`. Le choix du noyau et de la longueur de fenêtre est laissé libre.\n",
    "- Échantillonner 10 nouvelles images de la loi estimée. On utilisera $\\texttt{kde.sample}$\n",
    "- Afficher 10 images tirées du dataset, puis les 10 images générées. Commenter.\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc819a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "X = load_digits().data\n",
    "\n",
    "# Use scikit-learn to estimate the density\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #\n",
    "\n",
    "\n",
    "# Generate 10 new samples\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #\n",
    "\n",
    "\n",
    "# Plot 10 images from the dataset and 10 fake images obtained by sampling\n",
    "\n",
    "# # # # # # # # #\n",
    "# YOUR CODE HERE #\n",
    "# # # # # # # # #"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50080096",
   "metadata": {},
   "source": [
    "\n",
    "----- Votre réponse ici -----"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
